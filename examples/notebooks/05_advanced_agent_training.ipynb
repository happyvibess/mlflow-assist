{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Agent Training with MLFlow-Assist üöÄ\n",
    "\n",
    "This notebook demonstrates advanced agent training capabilities including:\n",
    "1. Multi-agent evolutionary training\n",
    "2. Meta-learning across different tasks\n",
    "3. Curriculum learning progression\n",
    "4. Performance visualization\n",
    "5. Advanced environment interactions\n",
    "\n",
    "[![Buy me a coffee](https://img.shields.io/badge/Buy%20me%20a%20coffee-happyvibess-orange)](https://www.buymeacoffee.com/happyvibess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mlflow_assist.agents import (\n",
    "    AdvancedTrainer,\n",
    "    AdvancedTrainingConfig,\n",
    "    RLAgent,\n",
    "    RLConfig\n",
    ")\n",
    "from mlflow_assist.agents.environments import (\n",
    "    CurriculumEnv,\n",
    "    TaskDifficulty,\n",
    "    MultiAgentEnv,\n",
    "    MetaLearningEnv\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-Agent Evolutionary Training üß¨\n",
    "\n",
    "Train a population of agents using evolutionary strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create base environment and agent\n",
    "env = gym.make('LunarLander-v2')\n",
    "config = RLConfig(\n",
    "    state_size=env.observation_space.shape[0],\n",
    "    action_size=env.action_space.n,\n",
    "    hidden_size=128\n",
    ")\n",
    "base_agent = RLAgent(config)\n",
    "\n",
    "# Configure evolutionary training\n",
    "trainer_config = AdvancedTrainingConfig(\n",
    "    population_size=20,\n",
    "    evolution_rate=0.1,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = AdvancedTrainer(\n",
    "    config=trainer_config,\n",
    "    base_agent=base_agent,\n",
    "    train_env=env,\n",
    "    experiment_name=\"lunar_lander_evolution\"\n",
    ")\n",
    "\n",
    "# Train population\n",
    "best_agent = trainer.train_population(\n",
    "    num_generations=50,\n",
    "    steps_per_generation=1000,\n",
    "    tournament_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Meta-Learning Across Tasks üéØ\n",
    "\n",
    "Train an agent that can quickly adapt to new tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create meta-learning environment\n",
    "class CustomMetaEnv(MetaLearningEnv):\n",
    "    def sample_tasks(self, num_tasks):\n",
    "        return [\n",
    "            {\"gravity\": np.random.uniform(-1.0, 0.0)}\n",
    "            for _ in range(num_tasks)\n",
    "        ]\n",
    "    \n",
    "    def set_task(self, task):\n",
    "        self.gravity = task[\"gravity\"]\n",
    "\n",
    "meta_env = CustomMetaEnv()\n",
    "\n",
    "# Configure meta-learning\n",
    "meta_config = AdvancedTrainingConfig(\n",
    "    meta_learning=True,\n",
    "    meta_lr=0.001,\n",
    "    num_tasks=5\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "meta_trainer = AdvancedTrainer(\n",
    "    config=meta_config,\n",
    "    base_agent=base_agent,\n",
    "    train_env=meta_env,\n",
    "    experiment_name=\"meta_learning\"\n",
    ")\n",
    "\n",
    "# Train with meta-learning\n",
    "meta_trainer.train_meta(\n",
    "    num_epochs=100,\n",
    "    tasks_per_batch=4,\n",
    "    adaptation_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Curriculum Learning üìö\n",
    "\n",
    "Train an agent with progressively harder tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create curriculum environment\n",
    "base_env = gym.make('BipedalWalker-v3')\n",
    "curr_env = CurriculumEnv(base_env)\n",
    "\n",
    "# Train with curriculum\n",
    "for difficulty in TaskDifficulty:\n",
    "    print(f\"\\nTraining at {difficulty.value} level...\")\n",
    "    curr_env.difficulty = difficulty\n",
    "    \n",
    "    # Train for this difficulty\n",
    "    trainer = AdvancedTrainer(\n",
    "        config=AdvancedTrainingConfig(curriculum_learning=True),\n",
    "        base_agent=base_agent,\n",
    "        train_env=curr_env,\n",
    "        experiment_name=f\"curriculum_{difficulty.value}\"\n",
    "    )\n",
    "    \n",
    "    trainer.train_population(\n",
    "        num_generations=20,\n",
    "        steps_per_generation=500\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Visualization üìà\n",
    "\n",
    "Analyze and visualize training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_training_curves(metrics_dict, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for metric_name, values in metrics_dict.items():\n",
    "        plt.plot(values, label=metric_name)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Generation/Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot evolutionary training progress\n",
    "evo_metrics = {\n",
    "    'Best Fitness': trainer.get_metrics('best_fitness'),\n",
    "    'Average Fitness': trainer.get_metrics('avg_fitness')\n",
    "}\n",
    "plot_training_curves(evo_metrics, 'Evolutionary Training Progress')\n",
    "\n",
    "# Plot meta-learning progress\n",
    "meta_metrics = {\n",
    "    'Meta Loss': meta_trainer.get_metrics('meta_loss'),\n",
    "    'Adaptation Rate': meta_trainer.get_metrics('adaptation_rate')\n",
    "}\n",
    "plot_training_curves(meta_metrics, 'Meta-Learning Progress')\n",
    "\n",
    "# Plot curriculum learning progress\n",
    "curr_metrics = {}\n",
    "for diff in TaskDifficulty:\n",
    "    curr_metrics[f'{diff.value}_performance'] = trainer.get_metrics(f'performance_{diff.value}')\n",
    "plot_training_curves(curr_metrics, 'Curriculum Learning Progress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Environment Interactions üåç\n",
    "\n",
    "Demonstrate complex environment handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create multi-agent environment\n",
    "class TeamEnvironment(MultiAgentEnv):\n",
    "    def __init__(self, num_agents=3):\n",
    "        super().__init__(num_agents)\n",
    "        self.agents = [gym.make('LunarLander-v2') for _ in range(num_agents)]\n",
    "    \n",
    "    def step(self, actions):\n",
    "        results = [env.step(a) for env, a in zip(self.agents, actions)]\n",
    "        states, rewards, dones, infos = zip(*results)\n",
    "        return list(states), list(rewards), list(dones), {}\n",
    "    \n",
    "    def reset(self):\n",
    "        return [env.reset() for env in self.agents]\n",
    "\n",
    "# Train team of agents\n",
    "team_env = TeamEnvironment(num_agents=3)\n",
    "team_config = AdvancedTrainingConfig(\n",
    "    num_agents=3,\n",
    "    self_play=True\n",
    ")\n",
    "\n",
    "team_trainer = AdvancedTrainer(\n",
    "    config=team_config,\n",
    "    base_agent=base_agent,\n",
    "    train_env=team_env,\n",
    "    experiment_name=\"team_training\"\n",
    ")\n",
    "\n",
    "# Train the team\n",
    "team_agents = team_trainer.train_population(\n",
    "    num_generations=30,\n",
    "    steps_per_generation=800\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps üéØ\n",
    "\n",
    "Try experimenting with:\n",
    "1. Different environments and tasks\n",
    "2. Custom evolutionary strategies\n",
    "3. More complex meta-learning setups\n",
    "4. Advanced curriculum design\n",
    "5. Custom multi-agent scenarios\n",
    "\n",
    "For more examples and documentation, check out:\n",
    "- [Documentation](../../docs/)\n",
    "- [Example Notebooks](../notebooks/)\n",
    "- [GitHub Repository](https://github.com/happyvibess/mlflow-assist)\n",
    "\n",
    "If this notebook helped you, consider [buying me a coffee](https://www.buymeacoffee.com/happyvibess)! ‚òïÔ∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

